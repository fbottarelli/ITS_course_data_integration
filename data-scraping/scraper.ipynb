{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.giallozafferano.it/'\n",
    "url = \"https://info.cern.ch/hypertext/WWW/TheProject.html\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2217"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(html_content)\n",
    "len(html_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the raw html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some simple ways to navigate that data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento <title> completo:                       <title>The World Wide Web project</title>\n",
      "Testo dell'elemento <title>:                     The World Wide Web project\n",
      "Nome del tag dell'elemento corrente:             title\n",
      "Nome del tag genitore dell'elemento <title>:     header\n"
     ]
    }
   ],
   "source": [
    "print(\"Elemento <title> completo:                      \", soup.title)\n",
    "print(\"Testo dell'elemento <title>:                    \", soup.title.string)\n",
    "print(\"Nome del tag dell'elemento corrente:            \", soup.title.name)\n",
    "print(\"Nome del tag genitore dell'elemento <title>:    \", soup.title.parent.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ci sono 25 link nella pagina\n"
     ]
    }
   ],
   "source": [
    "# All links in the page\n",
    "nb_links = len(soup.find_all('a'))\n",
    "print(f\"Ci sono {nb_links} link nella pagina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The World Wide Web project\n",
      "\n",
      "\n",
      "\n",
      "World Wide WebThe WorldWideWeb (W3) is a wide-area\n",
      "hypermedia information retrieval\n",
      "initiative aiming to give universal\n",
      "access to a large universe of documents.\n",
      "Everything there is online about\n",
      "W3 is linked directly or indirectly\n",
      "to this document, including an executive\n",
      "summary of the project, Mailing lists\n",
      ", Policy , November's  W3  news ,\n",
      "Frequently Asked Questions .\n",
      "\n",
      "What's out there?\n",
      " Pointers to the\n",
      "world's online information, subjects\n",
      ", W3 servers, etc.\n",
      "Help\n",
      " on the browser you are using\n",
      "Software Products\n",
      " A list of W3 project\n",
      "components and their current state.\n",
      "(e.g. Line Mode ,X11 Viola ,  NeXTStep\n",
      ", Servers , Tools , Mail robot ,\n",
      "Library )\n",
      "Technical\n",
      " Details of protocols, formats,\n",
      "program internals etc\n",
      "Bibliography\n",
      " Paper documentation\n",
      "on  W3 and references.\n",
      "People\n",
      " A list of some people involved\n",
      "in the project.\n",
      "History\n",
      " A summary of the history\n",
      "of the project.\n",
      "How can I help ?\n",
      " If you would like\n",
      "to support the web..\n",
      "Getting code\n",
      " Getting the code by\n",
      "anonymous FTP , etc.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text from the page\n",
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to select DOM elements from its tag `(<p>, <a>, <span>, ....)` you can simply do `soup.<tag>` to select it. The caveat is that it will only select the first HTML element with that tag.\n",
    "\n",
    "For example if I want the first link I just have to access the a field of my BeautifulSoup object\n",
    "\n",
    "And if you don't want the first matching element but instead all matching elements, just replace find with find_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a id=\"top\"></a>\n"
     ]
    }
   ],
   "source": [
    "first_link = soup.a\n",
    "print(first_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# The text of the link\n",
    "print(first_link.text)\n",
    "# The href of the link\n",
    "print(first_link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example. If you want to select the first element based on its id or class attributes, it is not much more difficult:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "pagespace = soup.find(id=\"pagespace\")\n",
    "print(pagespace)\n",
    "# class is a reserved keyword in Python, hence the '_'\n",
    "athing = soup.find(class_=\"athing\")\n",
    "print(athing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/wiki/ISBN', 22), ('/wiki/1555', 19), ('/wiki/1516', 17)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_hrefs = [a.get('href') for a in soup.find_all('a')]\n",
    "top_3_links = Counter(all_hrefs).most_common(3)\n",
    "print(top_3_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic element selection\n",
    "So far we've always passed a static tag type, however find_all is more versatile and does support dynamic selections as well. For example, we could pass a function reference and find_all will invoke your function for each element and only include that element only if your function returned true.\n",
    "\n",
    "In the following code sample we defined a function my_tag_selector which takes a tag parameter and returns true only if it got an <a> tag with an HTML class titlelink. Essentially, we extract only the article links from the main page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"hnuser\" href=\"user?id=Anon84\">Anon84</a>, <a class=\"hnuser\" href=\"user?id=ttfkam\">ttfkam</a>, <a class=\"hnuser\" href=\"user?id=WhyUVoteGarbage\">WhyUVoteGarbage</a>, <a class=\"hnuser\" href=\"user?id=rbanffy\">rbanffy</a>, <a class=\"hnuser\" href=\"user?id=zdw\">zdw</a>, <a class=\"hnuser\" href=\"user?id=thesephist\">thesephist</a>, <a class=\"hnuser\" href=\"user?id=luu\">luu</a>, <a class=\"hnuser\" href=\"user?id=Hooke\">Hooke</a>, <a class=\"hnuser\" href=\"user?id=tintinnabula\">tintinnabula</a>, <a class=\"hnuser\" href=\"user?id=writeslowly\">writeslowly</a>, <a class=\"hnuser\" href=\"user?id=kylegalbraith\">kylegalbraith</a>, <a class=\"hnuser\" href=\"user?id=rbanffy\">rbanffy</a>, <a class=\"hnuser\" href=\"user?id=tomalpha\">tomalpha</a>, <a class=\"hnuser\" href=\"user?id=pabs3\">pabs3</a>, <a class=\"hnuser\" href=\"user?id=kuba-orlik\">kuba-orlik</a>, <a class=\"hnuser\" href=\"user?id=kls0e\">kls0e</a>, <a class=\"hnuser\" href=\"user?id=ingve\">ingve</a>, <a class=\"hnuser\" href=\"user?id=surprisetalk\">surprisetalk</a>, <a class=\"hnuser\" href=\"user?id=piterrro\">piterrro</a>, <a class=\"hnuser\" href=\"user?id=skanderbm\">skanderbm</a>, <a class=\"hnuser\" href=\"user?id=jonsson101\">jonsson101</a>, <a class=\"hnuser\" href=\"user?id=kolchinski\">kolchinski</a>, <a class=\"hnuser\" href=\"user?id=benbreen\">benbreen</a>, <a class=\"hnuser\" href=\"user?id=wslh\">wslh</a>, <a class=\"hnuser\" href=\"user?id=bjhess\">bjhess</a>, <a class=\"hnuser\" href=\"user?id=vinnyglennon\">vinnyglennon</a>, <a class=\"hnuser\" href=\"user?id=PaulHoule\">PaulHoule</a>, <a class=\"hnuser\" href=\"user?id=Thevet\">Thevet</a>, <a class=\"hnuser\" href=\"user?id=Garbage\">Garbage</a>, <a class=\"morelink\" href=\"?p=2\" rel=\"next\">More</a>]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def my_tag_selector(tag):\n",
    "\t# We only accept \"a\" tags with a titlelink class\n",
    "\treturn tag.name == \"a\" and tag.has_attr(\"class\") and \"titlelink\"# in tag.get(\"class\")\n",
    "\n",
    "response = requests.get(\"https://news.ycombinator.com/\")\n",
    "if response.status_code != 200:\n",
    "\tprint(\"Error fetching page\")\n",
    "\texit()\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "print(soup.find_all(my_tag_selector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_all does not only support static strings as filter, but rather follows a generic \"true-ness\" approach, where you can pass different types of expressions and they just need to evaluate to true. Apart from tag strings and functions, there currently is also support for regular expressions and lists. In addition to find_all, there are also other functions to navigate the DOM tree, for example selecting the following DOM siblings or the element's parent.\n",
    "\n",
    "BeautifulSoup is a great example of a library that is both, easy to use and powerful. We mostly talked about selecting and finding elements so far, but you can also change and update the whole DOM tree. These bits, we won't cover in this article, however, because it's now time for CSS selectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS selectors\n",
    "Why learn about CSS selectors if BeautifulSoup already has a way to select elements based on their attributes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying the DOM\n",
    "Often, DOM elements do not have proper IDs or class names. While perfectly possible (see our previous examples, please), selecting elements in that case can be rather verbose and require lots of manual steps.\n",
    "\n",
    "For example, let's say that you want to extract the score of a post on the HN homepage, but you can't use class name or id in your code. Here is how you could do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "all_tr = soup.find_all('tr')\n",
    "for tr in all_tr:\n",
    "\tif len(tr.contents) == 2:\n",
    "\t\tprint(len(tr.contents[1]))\n",
    "\t\tif len(tr.contents[0].contents) == 0 and len(tr.contents[1].contents) == 13:\n",
    "\t\t\tpoints = tr.contents[1].text.split(' ')[0].strip()\n",
    "\t\t\tresults.append(points)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As promised, rather verbose, isn't it?\n",
    "\n",
    "This is exactly where CSS selectors shine. They allow you to break down your loop and ifs into one expression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hacker', '218', '36', '89', '87', '41', '45', '57', '116', '46', '71', '100', '36', '3', '161', '201', '176', '206', '10', '8', '48', '165', '80', '19', '3', '17', '56', '302', '109', '39', '77']\n"
     ]
    }
   ],
   "source": [
    "all_results = soup.select('td:nth-child(2) > span:nth-child(1)')\n",
    "results = [r.text.split(' ')[0].strip() for r in all_results]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key here is td:nth-child(2) > span:nth-child(1). This selects for us the first <span> which is an immediate child of a <td>, which itself has to be the second element of its parent (<tr>). The following HTML illustrates a valid DOM excerpt for our selector.\n",
    "```\n",
    "<tr>\n",
    "    <td>not the second child, are we?</td>\n",
    "    <td>\n",
    "        <span>HERE WE GO</span>\n",
    "        <span>this time not the first span</span>\n",
    "    </td>\n",
    "</tr>\n",
    "```\n",
    "This is much clearer and simpler, right? Of course, this example artificially highlights the usefulness of the CSS selector. But after playing a while with the DOM, you will fairly quickly realise how powerful CSS selectors are, especially when you cannot only rely on IDs or class names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue: https://www.scrapingbee.com/blog/python-web-scraping-beautiful-soup/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web-scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
